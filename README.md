


# ğŸš€ GitHub RAG Portfolio Assistant

An intelligent **Retrieval-Augmented Generation (RAG)** system for managing and exploring your GitHub portfolio.  
This project combines **vector search, query fusion, reranking, and conversational AI** to make your repositories easily searchable and showcaseable through natural language queries.

---
![Demo GIF](static/demo.gif)

---

## ğŸ“ Introduction

As your GitHub portfolio grows, it becomes harder to **track, organize, and present** your projects effectively.  
This assistant provides a smart interface to:

- ğŸ“¥ **Fetch & summarize** GitHub repositories  
- ğŸ“Š **Embed & index** projects in a vector database  
- ğŸ” **Retrieve projects** via conversational queries  
- ğŸ’¬ Support both **normal chat** and **retrieval-augmented workflows**  

Think of it as your **personal AI assistant for your portfolio**.

---

## âœ¨ Features

- ğŸ”„ **Conversational query preprocessing** â†’ Improves search relevance by rewriting ambiguous queries  
- ğŸ¯ **RAG Fusion** â†’ Generates multiple query variations for broader retrieval coverage  
- ğŸ“š **Reciprocal Rank Fusion (RRF)** â†’ Combines results from multiple queries for robust ranking  
- âš¡ **Cross-Encoder reranking** â†’ High-precision ranking using `cross-encoder/ms-marco-MiniLM-L-2-v2`  
- ğŸª¶ **Lightweight embeddings** â†’ `all-MiniLM-L6-v2` (384-dim) for a speed/accuracy trade-off  
- ğŸ”€ **Dual chat modes** â†’ Normal LLM chat & retrieval-augmented chat  
- ğŸ¤– **Agentic workflows** â†’ Routing between retrieval & normal chat with **LangGraph**  
- ğŸ“¦ **JSON-serializable outputs** â†’ Easy integration with other systems  
- ğŸ›  **Logging & config management** â†’ Debuggable & reproducible workflows  
- ğŸ““ **Example notebooks** â†’ Data ingestion & LangGraph experimentation  

---

## ğŸ—ï¸ Architecture

### ğŸ”¹ Data Ingestion Pipeline
- Fetches GitHub repos via API  
- Cleans and summarizes metadata  
- Embeds & stores in **Pinecone**  
- Orchestrated & schedulable for auto-updates  

### ğŸ”¹ Retrieval Pipeline
- Embedding-based search  
- Query rewriting + fusion  
- **Reciprocal Rank Fusion (RRF)**  
- Cross-encoder reranking for precision  

### ğŸ”¹ Chat Layer
- Normal **LLM conversations**  
- **Retrieval-augmented responses** when project context is required  
- Workflow routing via **LangGraph**  

### ğŸ”¹ Interface Layer
- **Streamlit UI** 
- Modular prompts (`prompts.py`) for maintainability  

---

## ğŸ” RAG Details

- **Embedding model**: `all-MiniLM-L6-v2` (384 dimensions)  
  - Optimized for CPU inference  
  - Balance of speed & semantic accuracy  

- **Reranker**: `cross-encoder/ms-marco-MiniLM-L-2-v2`  
  - Lightweight reranker for high-precision ranking  
  - Swappable with larger cross-encoders in GPU environments  

- **Query Fusion**:  
  - Multiple rewritten queries â†’ retrieved separately  
  - Combined using **Reciprocal Rank Fusion (RRF)**  

---

## âš™ï¸ Tech Stack

- **Core**: Python, GitHub API  
- **RAG Framework**: LangGraph, Pinecone, Sentence Transformers  
- **Models**:  
  - Embedding â†’ `all-MiniLM-L6-v2`  
  - Reranker â†’ `cross-encoder/ms-marco-MiniLM-L-2-v2`  
- **Interface**: Streamlit  
- **Infrastructure**: Docker, CI/CD, AWS (ECR + ECS Fargate)  
- **Other**: Groq, Structured Logging, Config Management  

---

## ğŸ“Œ Roadmap

- [x] Data ingestion & summarization  
- [x] Retrieval pipeline with query fusion + reranking  
- [x] Dual chat (retrieval & normal)  
- [x] Streamlit UI integration  
- [ ] Full Docker + AWS deployment pipeline  

---

### Project stucture

```
ğŸ“¦ project-root/
â”œâ”€â”€ app/  
â”‚   â”œâ”€â”€ app.py                # Streamlit/FastAPI entry point  
â”‚   â””â”€â”€ __init__.py  
â”‚
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ __init__.py  
â”‚   â”œâ”€â”€ build_index.py        # Embedding/index pipeline  
â”‚   â”œâ”€â”€ chat.py               # Chat agent logic with memory  
â”‚   â”œâ”€â”€ fetch_github.py       # Fetch GitHub data  
â”‚   â”œâ”€â”€ prompts.py            # Prompt templates  
â”‚   â””â”€â”€ retriever.py          # Retrieval logic  
â”‚
â”œâ”€â”€ utils/  
â”‚   â”œâ”€â”€ __init__.py  
â”‚   â”œâ”€â”€ config_loader.py  
â”‚   â”œâ”€â”€ custom_logger.py  
â”‚   â””â”€â”€ llm_client.py  
â”‚
â”œâ”€â”€ Pipelines/  
â”‚   â””â”€â”€ Data_Ingestion.py     # Data ingestion pipeline  
â”‚
â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ github/  
â”‚   â”‚   â”œâ”€â”€ projects.jsonl  
â”‚   â”‚   â”œâ”€â”€ github_readmes/   # Project README markdowns (.md files)  
â”‚   â”‚   â””â”€â”€ summaries/        # JSON summaries of README files  
â”‚
â”œâ”€â”€ notebooks/                # Keep for experiments (optional in prod)  
â”‚   â”œâ”€â”€ github_ingestion.ipynb  
â”‚   â””â”€â”€ langgraph_chat.ipynb  
â”‚
â”œâ”€â”€ static/  
â”‚   â”œâ”€â”€ demo.gif  
â”‚   â””â”€â”€ css/  
â”‚       â””â”€â”€ style.css  
â”‚
â”œâ”€â”€ logs/                     # Keep logs, but rotate in prod  
â”‚   â”œâ”€â”€ main.log  
â”‚   â”œâ”€â”€ build_index.log  
â”‚   â”œâ”€â”€ chat.log  
â”‚   â”œâ”€â”€ rag.log  
â”‚   â””â”€â”€ retriever.log  
â”‚
â”œâ”€â”€ .dockerignore  
â”œâ”€â”€ Dockerfile  
â”œâ”€â”€ requirements.txt  
â”œâ”€â”€ config.yaml  
â”œâ”€â”€ README.md  
â””â”€â”€ .gitignore  

```


