{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3217a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air_quality_Forecasting https://github.com/cleavestone/Air_quality_Forecasting\n",
      "CARLIFORNIA-HOUSE-PREDICTION https://github.com/cleavestone/CARLIFORNIA-HOUSE-PREDICTION\n",
      "ChestXray-Cancer-Detection https://github.com/cleavestone/ChestXray-Cancer-Detection\n",
      "Customer-Segmentation https://github.com/cleavestone/Customer-Segmentation\n",
      "Customer_Churn_MLOPS https://github.com/cleavestone/Customer_Churn_MLOPS\n",
      "DATA-ANALYSIS-SQL https://github.com/cleavestone/DATA-ANALYSIS-SQL\n",
      "Data-Analytics https://github.com/cleavestone/Data-Analytics\n",
      "Data-Insights-Hub https://github.com/cleavestone/Data-Insights-Hub\n",
      "ETL https://github.com/cleavestone/ETL\n",
      "fine_tuning_bert_model https://github.com/cleavestone/fine_tuning_bert_model\n",
      "MCQ_GEN https://github.com/cleavestone/MCQ_GEN\n",
      "Medical-chatbot https://github.com/cleavestone/Medical-chatbot\n",
      "mlflow-production-setup https://github.com/cleavestone/mlflow-production-setup\n",
      "Mlprojects https://github.com/cleavestone/Mlprojects\n",
      "Movie_recommender https://github.com/cleavestone/Movie_recommender\n",
      "Movie_Recommender_App https://github.com/cleavestone/Movie_Recommender_App\n",
      "Northwind-Sales-Analysis https://github.com/cleavestone/Northwind-Sales-Analysis\n",
      "portfolio https://github.com/cleavestone/portfolio\n",
      "RAG_from_scratch https://github.com/cleavestone/RAG_from_scratch\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "username = \"cleavestone\"\n",
    "\n",
    "headers = {\"Authorization\": f\"token {token}\"}\n",
    "url = f\"https://api.github.com/users/{username}/repos\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "repos = response.json()\n",
    "\n",
    "for repo in repos:\n",
    "    print(repo[\"name\"], repo[\"html_url\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b300f3a6",
   "metadata": {},
   "source": [
    "### Fetch README for Each Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d6dce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README for Air_quality_Forecasting:\n",
      " # Air_quality_Forecasting\n",
      "![](https://github.com/cleavestone/Air_quality_Forecasting/blob/main/forecast.png)\n",
      "## Introduction\n",
      "This project focuses on implementing a Long Short-Term Memory (LSTM) neural network for multivariate time series forecasting. The goal is to predict the PM2.5 concentration, a \n",
      "---\n",
      "\n",
      "README for CARLIFORNIA-HOUSE-PREDICTION:\n",
      " # CARLIFORNIA-HOUSE-PREDICTION\n",
      "\n",
      "br>\n",
      "\n",
      "<img src=\"https://github.com/cleavestone/CARLIFORNIA-HOUSE-PREDICTION/blob/main/static/image3.jpg\" alt=\"Image description\" width=\"1200\" height=\"1000\">\n",
      "\n",
      "<br>\n",
      "\n",
      "The US Census Bureau has published California Census Data which has 10 types of metrics such as the popul \n",
      "---\n",
      "\n",
      "README for ChestXray-Cancer-Detection:\n",
      " # ü´Å Chest X-ray Cancer Classification (Normal vs Adenocarcinoma)\n",
      "\n",
      "This repository contains an **end-to-end Deep Learning project** for classifying **chest X-rays** into **Normal** and **Adenocarcinoma** categories.  \n",
      "The project is designed with a **modular, production-ready pipeline**, integrating  \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for repo in repos[:3]:\n",
    "    repo_name = repo[\"name\"]\n",
    "    readme_url = f\"https://api.github.com/repos/{username}/{repo_name}/readme\"\n",
    "    res = requests.get(readme_url, headers=headers)\n",
    "\n",
    "    if res.status_code == 200:\n",
    "        readme_data = res.json()\n",
    "        import base64\n",
    "        content = base64.b64decode(readme_data[\"content\"]).decode(\"utf-8\")\n",
    "        print(f\"README for {repo_name}:\\n\", content[:300], \"\\n---\\n\")\n",
    "    else:\n",
    "        print(f\"No README found for {repo_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6594b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "os.makedirs(\"data/github_readmes\", exist_ok=True)\n",
    "\n",
    "for repo in repos:\n",
    "    repo_name = repo[\"name\"]\n",
    "    repo_url = repo[\"html_url\"]\n",
    "    readme_url = f\"https://api.github.com/repos/{username}/{repo_name}/readme\"\n",
    "    res = requests.get(readme_url, headers=headers)\n",
    "\n",
    "    if res.status_code == 200:\n",
    "        readme_data = res.json()\n",
    "        content = base64.b64decode(readme_data[\"content\"]).decode(\"utf-8\")\n",
    "\n",
    "        # Prepend repo URL\n",
    "        content_with_url = f\"# Repository: {repo_name}\\nURL: {repo_url}\\n\\n---\\n\\n{content}\"\n",
    "\n",
    "        with open(f\"data/github_readmes/{repo_name}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content_with_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73696012",
   "metadata": {},
   "source": [
    "### Regex Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd69a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_readme(text: str) -> str:\n",
    "    # Remove image badges (shields.io, CI/CD)\n",
    "    text = re.sub(r\"!\\[.*?\\]\\(.*?\\)\", \"\", text)\n",
    "\n",
    "    # Remove HTML comments\n",
    "    text = re.sub(r\"<!--.*?-->\", \"\", text, flags=re.S)\n",
    "\n",
    "    # Remove code blocks (``` ... ```)\n",
    "    text = re.sub(r\"```.*?```\", \"\", text, flags=re.S)\n",
    "\n",
    "    # Remove long URLs (just noise in many cases)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Collapse extra whitespace/newlines\n",
    "    text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8237f8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned: Air_quality_Forecasting.md\n",
      "‚úÖ Cleaned: CARLIFORNIA-HOUSE-PREDICTION.md\n",
      "‚úÖ Cleaned: ChestXray-Cancer-Detection.md\n",
      "‚úÖ Cleaned: Customer-Segmentation.md\n",
      "‚úÖ Cleaned: Customer_Churn_MLOPS.md\n",
      "‚úÖ Cleaned: DATA-ANALYSIS-SQL.md\n",
      "‚úÖ Cleaned: Data-Analytics.md\n",
      "‚úÖ Cleaned: Data-Insights-Hub.md\n",
      "‚úÖ Cleaned: ETL.md\n",
      "‚úÖ Cleaned: fine_tuning_bert_model.md\n",
      "‚úÖ Cleaned: MCQ_GEN.md\n",
      "‚úÖ Cleaned: Medical-chatbot.md\n",
      "‚úÖ Cleaned: mlflow-production-setup.md\n",
      "‚úÖ Cleaned: Mlprojects.md\n",
      "‚úÖ Cleaned: Movie_recommender.md\n",
      "‚úÖ Cleaned: Movie_Recommender_App.md\n",
      "‚úÖ Cleaned: Northwind-Sales-Analysis.md\n",
      "‚úÖ Cleaned: portfolio.md\n",
      "‚úÖ Cleaned: RAG_from_scratch.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Input + Output folders\n",
    "input_folder = \"data/github_readmes\"\n",
    "output_folder = \"data/cleaned_readmes\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop over all markdown files\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".md\"):\n",
    "        input_path = os.path.join(input_folder, file_name)\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_text = f.read()\n",
    "\n",
    "        cleaned_text = clean_readme(raw_text)\n",
    "\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(cleaned_text)\n",
    "\n",
    "        print(f\"‚úÖ Cleaned: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4a2d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "def summarize_for_embeddings(repo_name, repo_url, text):\n",
    "    # Check if API key exists\n",
    "    api_key = os.getenv('GROQ_API_KEY')\n",
    "    if not api_key:\n",
    "        return {\n",
    "            \"repo_name\": repo_name,\n",
    "            \"repo_url\": repo_url,\n",
    "            \"error\": \"GROQ_API_KEY not found in environment variables\"\n",
    "        }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are preparing project data for a Retrieval-Augmented Generation (RAG) system.\n",
    "The input is a README file that may contain tables, images, code, or badges.\n",
    "Your task is to extract the most important structured information.\n",
    "\n",
    "Guidelines:\n",
    "- Summarize into 2‚Äì4 sentences: purpose, approach, and why it matters.\n",
    "- Extract `key_skills` (methods, ML techniques, analytical skills).\n",
    "- Extract `tech_stack` (frameworks, libraries, tools, languages).\n",
    "- Suggest 2 realistic `use_cases` based on the project's purpose.\n",
    "- Assign `complexity_level` as Beginner, Intermediate, or Advanced.\n",
    "- Extract `tags` to help categorize projects (e.g., \"machine learning\", \"time series\", \"kmeans clustering\").\n",
    "- If information is missing, set it to \"Unknown\".\n",
    "- Ignore irrelevant details like install instructions, badges, license, or author credits.\n",
    "\n",
    "‚ö†Ô∏è Output must be ONLY valid JSON, no markdown, no commentary.\n",
    "\n",
    "Required fields:\n",
    "- repo_name: {repo_name}\n",
    "- repo_url: {repo_url}\n",
    "- description\n",
    "- key_skills (list)\n",
    "- tech_stack (list)\n",
    "- use_cases (list)\n",
    "- complexity_level\n",
    "- tags (list)\n",
    "\n",
    "README:\n",
    "{text[:6000]}\n",
    "\"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"llama-3.3-70b-versatile\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise summarizer that outputs only valid JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.2\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=data,\n",
    "            timeout=30  # Add timeout to prevent hanging\n",
    "        )\n",
    "        response.raise_for_status()  # Raise exception for bad status codes\n",
    "        resp_json = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\n",
    "            \"repo_name\": repo_name,\n",
    "            \"repo_url\": repo_url,\n",
    "            \"error\": f\"Request failed: {str(e)}\"\n",
    "        }\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"repo_name\": repo_name,\n",
    "            \"repo_url\": repo_url,\n",
    "            \"error\": \"Invalid JSON response from API\"\n",
    "        }\n",
    "\n",
    "    if \"error\" in resp_json:\n",
    "        return {\"repo_name\": repo_name, \"repo_url\": repo_url, \"error\": resp_json[\"error\"]}\n",
    "\n",
    "    if \"choices\" not in resp_json:\n",
    "        return {\"repo_name\": repo_name, \"repo_url\": repo_url, \"error\": \"No choices in response\"}\n",
    "\n",
    "    raw_output = resp_json[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "    # Remove markdown code blocks if present\n",
    "    if raw_output.startswith(\"```\"):\n",
    "        raw_output = raw_output.split(\"```\")[1]\n",
    "        if raw_output.startswith(\"json\"):\n",
    "            raw_output = raw_output[4:].strip()\n",
    "\n",
    "    try:\n",
    "        summary = json.loads(raw_output)\n",
    "    except json.JSONDecodeError:\n",
    "        # fallback: best-effort extraction\n",
    "        summary = {\n",
    "            \"repo_name\": repo_name,\n",
    "            \"repo_url\": repo_url,\n",
    "            \"description\": raw_output,\n",
    "            \"key_skills\": [],\n",
    "            \"tech_stack\": [],\n",
    "            \"use_cases\": [],\n",
    "            \"complexity_level\": \"Unknown\",\n",
    "            \"tags\": []\n",
    "        }\n",
    "\n",
    "    # Ensure required fields exist\n",
    "    summary.setdefault(\"repo_name\", repo_name)\n",
    "    summary.setdefault(\"repo_url\", repo_url)\n",
    "    summary.setdefault(\"description\", \"Unknown\")\n",
    "    summary.setdefault(\"key_skills\", [])\n",
    "    summary.setdefault(\"tech_stack\", [])\n",
    "    summary.setdefault(\"use_cases\", [])\n",
    "    summary.setdefault(\"complexity_level\", \"Unknown\")\n",
    "    summary.setdefault(\"tags\", [])\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f0bf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summarized: Air_quality_Forecasting\n",
      "‚úÖ Summarized: CARLIFORNIA-HOUSE-PREDICTION\n",
      "‚úÖ Summarized: ChestXray-Cancer-Detection\n",
      "‚úÖ Summarized: Customer-Segmentation\n",
      "‚úÖ Summarized: Customer_Churn_MLOPS\n",
      "‚úÖ Summarized: DATA-ANALYSIS-SQL\n",
      "‚úÖ Summarized: Data-Analytics\n",
      "‚úÖ Summarized: Data-Insights-Hub\n",
      "‚úÖ Summarized: ETL\n",
      "‚úÖ Summarized: fine_tuning_bert_model\n",
      "‚úÖ Summarized: MCQ_GEN\n",
      "‚úÖ Summarized: Medical-chatbot\n",
      "‚úÖ Summarized: mlflow-production-setup\n",
      "‚úÖ Summarized: Mlprojects\n",
      "‚úÖ Summarized: Movie_recommender\n",
      "‚úÖ Summarized: Movie_Recommender_App\n",
      "‚úÖ Summarized: Northwind-Sales-Analysis\n",
      "‚úÖ Summarized: portfolio\n",
      "‚úÖ Summarized: RAG_from_scratch\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "input_folder=\"data/github_readmes\"\n",
    "output_folder=\"data/summarized_readmes\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "for i, file_name in enumerate(os.listdir(input_folder)):\n",
    "    if file_name.endswith(\".md\"):\n",
    "        repo_name = file_name.replace(\".md\", \"\")\n",
    "        repo_url = f\"https://github.com/cleave/{repo_name}\"\n",
    "\n",
    "        with open(os.path.join(input_folder, file_name), \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        summary = summarize_for_embeddings(repo_name, repo_url, text)\n",
    "\n",
    "        with open(os.path.join(output_folder, repo_name + \".json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "\n",
    "        print(f\"‚úÖ Summarized: {repo_name}\")\n",
    "\n",
    "        # Sleep to avoid rate limit\n",
    "        time.sleep(6)  # adjust depending on TPM limit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e4aa7d",
   "metadata": {},
   "source": [
    "### Merge Jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd704ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def combine_jsons_to_jsonl(input_folder=\"data/summarized_readmes\", output_file=\"data/summarized_readmes.jsonl\"):\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for filename in os.listdir(input_folder):\n",
    "            if filename.endswith(\".json\"):\n",
    "                file_path = os.path.join(input_folder, filename)\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "                    try:\n",
    "                        data = json.load(infile)  # load each json file\n",
    "                        outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"‚ö†Ô∏è Skipping {filename}, invalid JSON\")\n",
    "\n",
    "    print(f\"‚úÖ Combined JSONL written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dc7ad6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined JSONL written to data/summarized_readmes.jsonl\n"
     ]
    }
   ],
   "source": [
    "combine_jsons_to_jsonl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42c09f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\Desktop\\RAG_PROJECT\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Hp\\Desktop\\RAG_PROJECT\\venv\\Lib\\site-packages\\langchain_pinecone\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c959d920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pinecone index: proj-index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Load .env\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"Missing Pinecone API key. Did you set it in your .env?\")\n",
    "\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "index_name = \"proj-index\"\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # Match SentenceTransformer embedding size\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    #pc.describe_index(index_name).wait_until_ready()\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to Pinecone index: {index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989e8156",
   "metadata": {},
   "source": [
    "### Load your cleaned JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23ccd9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "with open(\"data/summarized_readmes.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        docs.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f40123f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repo_name': 'Air_quality_Forecasting',\n",
       " 'repo_url': 'https://github.com/cleavestone/Air_quality_Forecasting',\n",
       " 'description': 'This project implements a Long Short-Term Memory (LSTM) neural network for multivariate time series forecasting to predict PM2.5 concentration using historical environmental data.',\n",
       " 'key_skills': ['Time series forecasting',\n",
       "  'LSTM neural networks',\n",
       "  'Feature engineering',\n",
       "  'Data preprocessing',\n",
       "  'Model evaluation'],\n",
       " 'tech_stack': ['Keras', 'Python', 'Min-Max scaling'],\n",
       " 'use_cases': ['Air quality prediction for environmental management',\n",
       "  'Time series forecasting for climate change research'],\n",
       " 'complexity_level': 'Intermediate',\n",
       " 'tags': ['machine learning',\n",
       "  'time series',\n",
       "  'LSTM',\n",
       "  'air quality forecasting']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc64b9",
   "metadata": {},
   "source": [
    "### Flatten documents (combine description + use_cases etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90f065e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_embedding(doc):\n",
    "    \"\"\"\n",
    "    Converts a project dictionary into a single text string optimized for embedding.\n",
    "    \n",
    "    Args:\n",
    "        doc (dict): Project metadata dictionary\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted text ready for embedding\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Add project name and description\n",
    "    parts.append(f\"Project: {doc.get('repo_name', 'Unknown')}\")\n",
    "    parts.append(f\"Description: {doc.get('description', 'No description available')}\")\n",
    "    \n",
    "    # Add key skills\n",
    "    skills = doc.get('key_skills', [])\n",
    "    if skills:\n",
    "        parts.append(f\"Key Skills: {', '.join(skills)}\")\n",
    "    \n",
    "    # Add tech stack\n",
    "    tech = doc.get('tech_stack', [])\n",
    "    if tech:\n",
    "        parts.append(f\"Technologies: {', '.join(tech)}\")\n",
    "    \n",
    "    # Add use cases\n",
    "    use_cases = doc.get('use_cases', [])\n",
    "    if use_cases:\n",
    "        parts.append(f\"Use Cases: {'; '.join(use_cases)}\")\n",
    "    \n",
    "    # Add complexity level\n",
    "    complexity = doc.get('complexity_level', 'Unknown')\n",
    "    parts.append(f\"Complexity: {complexity}\")\n",
    "    \n",
    "    # Add tags\n",
    "    tags = doc.get('tags', [])\n",
    "    if tags:\n",
    "        parts.append(f\"Tags: {', '.join(tags)}\")\n",
    "    \n",
    "    # Join all parts with newlines\n",
    "    return '\\n'.join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f5bae8",
   "metadata": {},
   "source": [
    "### Generate Embeddings with sBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab68c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e851d11b-73b6-48cf-a5af-7f3648b7f851)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Use any sBERT model (384-dim is typical for MiniLM)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # dim=384\n",
    "\n",
    "vectors = []\n",
    "for i, doc in enumerate(docs):\n",
    "    text = prepare_text_for_embedding(doc)\n",
    "    emb = model.encode(text).tolist()  # convert to list for Pinecone\n",
    "\n",
    "    vectors.append({\n",
    "        \"id\": doc.get(\"repo_name\", f\"doc-{i}\"),\n",
    "        \"values\": emb,\n",
    "        \"metadata\": {\n",
    "            \"repo_name\": doc.get(\"repo_name\", \"unknown\"),\n",
    "            \"repo_url\": doc.get(\"repo_url\", \"unknown\"),\n",
    "            \"description\": doc.get(\"description\", \"\"),\n",
    "            \"tech_stack\": doc.get(\"tech_stack\", []),\n",
    "            \"skills\": doc.get(\"key_skills\", []),\n",
    "            \"use_cases\": doc.get(\"use_cases\", []),\n",
    "            \"complexity\": doc.get(\"complexity_level\", \"\")\n",
    "        }\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3c78a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Northwind-Sales-Analysis',\n",
       " 'values': [0.019042545929551125,\n",
       "  0.03667434677481651,\n",
       "  -0.048668745905160904,\n",
       "  -0.011946066282689571,\n",
       "  -0.12781919538974762,\n",
       "  0.01429382711648941,\n",
       "  -0.006978760007768869,\n",
       "  -0.03406502678990364,\n",
       "  -0.04196447879076004,\n",
       "  -0.018293412402272224,\n",
       "  -0.06484587490558624,\n",
       "  0.019540147855877876,\n",
       "  0.06442423164844513,\n",
       "  -0.02072153240442276,\n",
       "  0.0010317630367353559,\n",
       "  0.03405885025858879,\n",
       "  0.04692571610212326,\n",
       "  -0.0499984472990036,\n",
       "  0.006551666185259819,\n",
       "  0.01413897518068552,\n",
       "  -0.031610555946826935,\n",
       "  0.0057698399759829044,\n",
       "  -0.056448884308338165,\n",
       "  -0.01695774681866169,\n",
       "  0.06309626996517181,\n",
       "  -0.02708897925913334,\n",
       "  0.03766566142439842,\n",
       "  0.01354946568608284,\n",
       "  -0.01626916229724884,\n",
       "  -0.06541453301906586,\n",
       "  -0.09043028205633163,\n",
       "  0.012773041613399982,\n",
       "  0.020328011363744736,\n",
       "  0.05851664021611214,\n",
       "  -0.04547664150595665,\n",
       "  -0.04380828142166138,\n",
       "  0.05624281242489815,\n",
       "  0.060844291001558304,\n",
       "  0.033567506819963455,\n",
       "  -0.011851618997752666,\n",
       "  -0.004698903765529394,\n",
       "  -0.06769886612892151,\n",
       "  -0.05222836509346962,\n",
       "  0.00435904273763299,\n",
       "  -0.011282212100923061,\n",
       "  -0.02124449796974659,\n",
       "  -0.09646566212177277,\n",
       "  -0.027729973196983337,\n",
       "  -0.01117745228111744,\n",
       "  0.08084271103143692,\n",
       "  -0.12178514152765274,\n",
       "  -0.07485082000494003,\n",
       "  -0.04250781238079071,\n",
       "  0.05315251275897026,\n",
       "  0.03287526220083237,\n",
       "  0.033036038279533386,\n",
       "  0.010887387208640575,\n",
       "  -0.06376276910305023,\n",
       "  0.007612805347889662,\n",
       "  0.012453838251531124,\n",
       "  0.03023218922317028,\n",
       "  -0.07621018588542938,\n",
       "  0.008818010799586773,\n",
       "  0.049630288034677505,\n",
       "  0.028787583112716675,\n",
       "  0.03691067174077034,\n",
       "  -0.02580154873430729,\n",
       "  0.09142094850540161,\n",
       "  -0.08321455866098404,\n",
       "  -0.1402651071548462,\n",
       "  -0.010573399253189564,\n",
       "  -0.05318445339798927,\n",
       "  -0.07898948341608047,\n",
       "  -0.005638516042381525,\n",
       "  -0.08546275645494461,\n",
       "  0.022968856617808342,\n",
       "  0.0027334699407219887,\n",
       "  -0.023060528561472893,\n",
       "  0.027733076363801956,\n",
       "  -0.05816490948200226,\n",
       "  -0.04707399383187294,\n",
       "  0.07886746525764465,\n",
       "  -0.1361059844493866,\n",
       "  0.1237223744392395,\n",
       "  0.032417964190244675,\n",
       "  -0.06464719027280807,\n",
       "  0.05507610738277435,\n",
       "  -0.01949787512421608,\n",
       "  -0.013627082109451294,\n",
       "  -0.017067795619368553,\n",
       "  0.005424213595688343,\n",
       "  0.100597083568573,\n",
       "  0.02038232423365116,\n",
       "  -0.061201851814985275,\n",
       "  0.004210471175611019,\n",
       "  -0.025094471871852875,\n",
       "  -0.09955648332834244,\n",
       "  -0.043901149183511734,\n",
       "  0.05900275334715843,\n",
       "  -0.01818181574344635,\n",
       "  0.04665341228246689,\n",
       "  0.12179366499185562,\n",
       "  0.0430135652422905,\n",
       "  -0.07083068042993546,\n",
       "  -0.1410088688135147,\n",
       "  -0.03899984434247017,\n",
       "  0.001317372894845903,\n",
       "  0.0454835519194603,\n",
       "  -0.014510462060570717,\n",
       "  -0.009413463063538074,\n",
       "  0.00561937503516674,\n",
       "  0.0005836591008119285,\n",
       "  -0.04504038393497467,\n",
       "  -0.1315208077430725,\n",
       "  0.015596439130604267,\n",
       "  0.047636471688747406,\n",
       "  -0.0708739385008812,\n",
       "  0.02125653065741062,\n",
       "  0.016632359474897385,\n",
       "  0.06577470898628235,\n",
       "  -0.013378605246543884,\n",
       "  0.08453955501317978,\n",
       "  -0.012987042777240276,\n",
       "  -0.04103367030620575,\n",
       "  0.0019297488033771515,\n",
       "  0.00441013602539897,\n",
       "  -0.029768379405140877,\n",
       "  2.8969852564503882e-33,\n",
       "  -0.07818203419446945,\n",
       "  0.013865912333130836,\n",
       "  0.017949966713786125,\n",
       "  0.0023407679982483387,\n",
       "  0.056670334190130234,\n",
       "  0.0018029781058430672,\n",
       "  -0.01842992566525936,\n",
       "  -0.008750888518989086,\n",
       "  -0.07089417427778244,\n",
       "  0.022249802947044373,\n",
       "  -0.0005765728419646621,\n",
       "  0.1978279948234558,\n",
       "  0.012082136236131191,\n",
       "  -0.005278936121612787,\n",
       "  0.07967140525579453,\n",
       "  0.0513596273958683,\n",
       "  0.049284886568784714,\n",
       "  0.06269753724336624,\n",
       "  -0.02460206300020218,\n",
       "  -0.021077709272503853,\n",
       "  0.0494527742266655,\n",
       "  -0.08311004936695099,\n",
       "  0.045486919581890106,\n",
       "  0.05795176699757576,\n",
       "  0.060957279056310654,\n",
       "  -0.007400432135909796,\n",
       "  0.020049111917614937,\n",
       "  0.05020144209265709,\n",
       "  0.027809543535113335,\n",
       "  0.016740448772907257,\n",
       "  0.10133378952741623,\n",
       "  -0.04350340738892555,\n",
       "  -0.029345029965043068,\n",
       "  0.01152818650007248,\n",
       "  -0.008748025633394718,\n",
       "  -0.02209337428212166,\n",
       "  0.012750964611768723,\n",
       "  -0.04766257852315903,\n",
       "  0.06321103125810623,\n",
       "  0.03668829798698425,\n",
       "  -0.1317678838968277,\n",
       "  0.0455932691693306,\n",
       "  -0.05858306959271431,\n",
       "  -0.02325034886598587,\n",
       "  -0.06926704198122025,\n",
       "  0.006556857377290726,\n",
       "  0.02098921127617359,\n",
       "  -0.012165057472884655,\n",
       "  0.10289059579372406,\n",
       "  0.04676859825849533,\n",
       "  -0.013430663384497166,\n",
       "  -0.041630253195762634,\n",
       "  0.019460801035165787,\n",
       "  0.06135621294379234,\n",
       "  -0.04403563216328621,\n",
       "  0.056797582656145096,\n",
       "  0.06890229135751724,\n",
       "  -0.039303261786699295,\n",
       "  0.012257952243089676,\n",
       "  0.017393214628100395,\n",
       "  -0.07837893068790436,\n",
       "  -0.015285219065845013,\n",
       "  -0.0027291784062981606,\n",
       "  -0.05908525735139847,\n",
       "  0.015483101829886436,\n",
       "  0.0034862514585256577,\n",
       "  0.0029449090361595154,\n",
       "  -0.0386882983148098,\n",
       "  0.01582295075058937,\n",
       "  -0.07282474637031555,\n",
       "  0.011671102605760098,\n",
       "  -0.021753516048192978,\n",
       "  0.060258422046899796,\n",
       "  -0.0006665621767751873,\n",
       "  0.058348845690488815,\n",
       "  -0.006155969575047493,\n",
       "  -0.08332172781229019,\n",
       "  0.03499753400683403,\n",
       "  0.04914354905486107,\n",
       "  0.039684005081653595,\n",
       "  -0.05206157639622688,\n",
       "  0.010350462049245834,\n",
       "  0.05045425519347191,\n",
       "  -0.07297278195619583,\n",
       "  0.04148828238248825,\n",
       "  -0.03291984647512436,\n",
       "  0.06931781023740768,\n",
       "  -0.0028744826558977365,\n",
       "  -0.07541628181934357,\n",
       "  0.01575043611228466,\n",
       "  -0.03391092270612717,\n",
       "  0.11464672535657883,\n",
       "  -0.039178140461444855,\n",
       "  0.0577625073492527,\n",
       "  0.00342756905592978,\n",
       "  -3.9847891980692716e-33,\n",
       "  -0.0382668562233448,\n",
       "  0.03230629488825798,\n",
       "  -0.04617372527718544,\n",
       "  0.030990876257419586,\n",
       "  0.06872529536485672,\n",
       "  0.04875751584768295,\n",
       "  -0.04490049183368683,\n",
       "  -0.08441255241632462,\n",
       "  0.029953954741358757,\n",
       "  0.013169225305318832,\n",
       "  -0.010594083927571774,\n",
       "  -0.031758565455675125,\n",
       "  -0.0047100563533604145,\n",
       "  -0.007913979701697826,\n",
       "  0.0834398940205574,\n",
       "  0.0007404244388453662,\n",
       "  0.037137720733881,\n",
       "  -0.043180957436561584,\n",
       "  -0.07129750400781631,\n",
       "  0.0235025342553854,\n",
       "  0.035269081592559814,\n",
       "  0.1253407597541809,\n",
       "  -0.05570247769355774,\n",
       "  0.031916745007038116,\n",
       "  -0.022709347307682037,\n",
       "  0.07515935599803925,\n",
       "  -0.031893596053123474,\n",
       "  -0.055522721260786057,\n",
       "  0.0587073378264904,\n",
       "  -0.0004206367884762585,\n",
       "  -0.05873633176088333,\n",
       "  -0.0660230815410614,\n",
       "  -0.007910775020718575,\n",
       "  0.02200520597398281,\n",
       "  -0.03789174184203148,\n",
       "  -0.030948461964726448,\n",
       "  0.06299112737178802,\n",
       "  -0.06566470861434937,\n",
       "  0.0575239397585392,\n",
       "  -0.0006653948221355677,\n",
       "  0.03997208923101425,\n",
       "  0.03500709682703018,\n",
       "  0.03796149045228958,\n",
       "  -0.053494200110435486,\n",
       "  -0.03376479819417,\n",
       "  -0.06366178393363953,\n",
       "  0.010919792577624321,\n",
       "  0.008044120855629444,\n",
       "  -0.009187730960547924,\n",
       "  -0.024543121457099915,\n",
       "  0.019312461838126183,\n",
       "  0.07595065236091614,\n",
       "  -0.022913318127393723,\n",
       "  0.021277934312820435,\n",
       "  -0.05065541714429855,\n",
       "  0.009043686091899872,\n",
       "  0.027683312073349953,\n",
       "  0.004319306928664446,\n",
       "  -0.07884081453084946,\n",
       "  -0.005490016657859087,\n",
       "  0.004877152387052774,\n",
       "  0.027877092361450195,\n",
       "  0.07007646560668945,\n",
       "  0.033359117805957794,\n",
       "  -0.011332938447594643,\n",
       "  0.006731626112014055,\n",
       "  0.045532211661338806,\n",
       "  -0.05379769578576088,\n",
       "  -0.042327847331762314,\n",
       "  -0.08118610084056854,\n",
       "  -0.06799193471670151,\n",
       "  0.027756407856941223,\n",
       "  0.044145770370960236,\n",
       "  -0.09401208907365799,\n",
       "  -0.07455670833587646,\n",
       "  0.001132563455030322,\n",
       "  0.006429338362067938,\n",
       "  -0.042407698929309845,\n",
       "  -0.0115098487585783,\n",
       "  0.045515723526477814,\n",
       "  0.008156239055097103,\n",
       "  0.04494417458772659,\n",
       "  0.014624157920479774,\n",
       "  0.028353936970233917,\n",
       "  0.025373607873916626,\n",
       "  0.0308719240128994,\n",
       "  -0.0008342974469996989,\n",
       "  -0.05057993158698082,\n",
       "  0.03410647064447403,\n",
       "  -0.05799788981676102,\n",
       "  -0.1392396241426468,\n",
       "  -0.07359969615936279,\n",
       "  -0.10070814937353134,\n",
       "  0.020203866064548492,\n",
       "  -0.00019864580826833844,\n",
       "  -4.093910987990057e-08,\n",
       "  -0.011321764439344406,\n",
       "  -0.04141318053007126,\n",
       "  -0.0009822651045396924,\n",
       "  0.06191745027899742,\n",
       "  0.0787467435002327,\n",
       "  -0.05901523306965828,\n",
       "  0.005251159891486168,\n",
       "  0.08777222037315369,\n",
       "  -0.07320306450128555,\n",
       "  0.04345053434371948,\n",
       "  0.1251014620065689,\n",
       "  -0.04717377573251724,\n",
       "  -0.05817152559757233,\n",
       "  -0.003547026077285409,\n",
       "  0.033078230917453766,\n",
       "  -0.030105285346508026,\n",
       "  0.06691081821918488,\n",
       "  0.0331730954349041,\n",
       "  -0.00843818485736847,\n",
       "  -0.027495548129081726,\n",
       "  0.04050755500793457,\n",
       "  0.032696668058633804,\n",
       "  0.0037815349642187357,\n",
       "  0.03163517266511917,\n",
       "  -0.005824459251016378,\n",
       "  0.010866095311939716,\n",
       "  -0.009882251732051373,\n",
       "  -0.013998902402818203,\n",
       "  0.0488530695438385,\n",
       "  -0.06475537270307541,\n",
       "  0.04368523508310318,\n",
       "  0.0034539096523076296,\n",
       "  0.05515187606215477,\n",
       "  -0.019633393734693527,\n",
       "  0.029266424477100372,\n",
       "  -0.03918786346912384,\n",
       "  0.047201577574014664,\n",
       "  0.09048325568437576,\n",
       "  -0.016719775274395943,\n",
       "  0.08330246061086655,\n",
       "  -0.01025963481515646,\n",
       "  -0.005860134027898312,\n",
       "  -0.037977173924446106,\n",
       "  0.062220051884651184,\n",
       "  -0.05665714666247368,\n",
       "  0.008813222870230675,\n",
       "  -0.11276358366012573,\n",
       "  -0.0308330450206995,\n",
       "  0.01284997258335352,\n",
       "  0.020087843760848045,\n",
       "  0.00642765499651432,\n",
       "  -0.048792514950037,\n",
       "  0.03158121183514595,\n",
       "  0.016749581322073936,\n",
       "  0.00656152842566371,\n",
       "  0.1228509321808815,\n",
       "  0.005811801180243492,\n",
       "  -0.015455856919288635,\n",
       "  -0.001241736696101725,\n",
       "  0.05217535421252251,\n",
       "  0.06027582287788391,\n",
       "  -0.03713607043027878,\n",
       "  -0.03963211178779602,\n",
       "  0.027828603982925415],\n",
       " 'metadata': {'repo_name': 'Northwind-Sales-Analysis',\n",
       "  'repo_url': 'https://github.com/cleavestone/Northwind-Sales-Analysis',\n",
       "  'description': 'This project analyzes Northwind database sales data using Power BI to uncover insights into sales, profit, orders, and delivery performance. The project connects Power BI to a local SQL Server, cleans and transforms data using Power Query, models data, and creates DAX measures for KPIs. The final report is published to the Power BI Service for online access and sharing.',\n",
       "  'tech_stack': ['Power BI', 'SQL Server', 'Power Query', 'DAX'],\n",
       "  'skills': ['Data Connection',\n",
       "   'Data Transformation',\n",
       "   'Data Modeling',\n",
       "   'DAX',\n",
       "   'Power Query',\n",
       "   'Power BI',\n",
       "   'SQL Server',\n",
       "   'Data Analysis',\n",
       "   'Data Visualization'],\n",
       "  'use_cases': ['Sales performance analysis for businesses',\n",
       "   'Data-driven decision making for companies using Power BI'],\n",
       "  'complexity': 'Intermediate'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0471700e",
   "metadata": {},
   "source": [
    "### Upload to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76f0447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded 19 vectors to Pinecone index 'proj-index'\n"
     ]
    }
   ],
   "source": [
    "# Upload in batches (to avoid limits)\n",
    "for i in range(0, len(vectors), 100):\n",
    "    batch = vectors[i : i+100]\n",
    "    index.upsert(vectors=batch)\n",
    "\n",
    "print(f\"‚úÖ Uploaded {len(vectors)} vectors to Pinecone index '{index_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bd652ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Top Matches:\n",
      "- https://github.com/cleavestone/Customer-Segmentation (0.444)\n",
      "  Description: This project applies RFM Analysis on transactional data from an e-commerce platform to identify distinct customer groups and recommend tailored engagement strategies for each. The project uses clustering techniques to segment customers based on their transaction patterns, enabling data-driven business decisions. The goal is to drive personalized marketing strategies and improve overall customer retention. The project provides actionable insights and visualizations to help businesses understand their customers better.\n",
      "- https://github.com/cleavestone/Data-Analytics (0.395)\n",
      "  Description: Unknown\n"
     ]
    }
   ],
   "source": [
    "query = \"Any projects on clustering\"\n",
    "\n",
    "q_emb = model.encode(query).tolist()\n",
    "\n",
    "results = index.query(vector=q_emb, top_k=2, include_metadata=True)\n",
    "\n",
    "print(\"üîç Top Matches:\")\n",
    "for match in results.matches:\n",
    "    print(f\"- {match.metadata['repo_url']} ({match.score:.3f})\")\n",
    "    print(\"  Description:\", match.metadata['description'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f915ffe",
   "metadata": {},
   "source": [
    "### Query Pinecone (Retrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afc614bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_pinecone(query, top_k=3):\n",
    "    q_emb = model.encode(query).tolist()\n",
    "    results = index.query(vector=q_emb, top_k=top_k, include_metadata=True)\n",
    "    return results.matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df333240",
   "metadata": {},
   "source": [
    "### Build Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6dd4bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(matches):\n",
    "    context = \"\"\n",
    "    for m in matches:\n",
    "        context += f\"- Repo_name: {m.metadata.get('repo_name','unknown')}\\n\"\n",
    "        context += f\"- Repo_Url: {m.metadata.get('repo_url', 'unknown')}\\n\"\n",
    "        context += f\"  Description: {m.metadata.get('description', '')}\\n\"\n",
    "        context += f\"  Tech: {', '.join(m.metadata.get('tech_stack', []))}\\n\"\n",
    "        context += f\"  Skills: {', '.join(m.metadata.get('skills', []))}\\n\"\n",
    "        context += f\"  Use Cases: {', '.join(m.metadata.get('use_cases', []))}\\n\\n\"\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff04594e",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "249515e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def generate_answer(query, context):\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant answering about my GitHub projects.\n",
    "\n",
    "    User query: {query}\n",
    "\n",
    "    Relevant project summaries:\n",
    "    {context}\n",
    "\n",
    "    Based on the above, provide a clear and concise answer.\n",
    "    If relevant, include the repo URL(s).\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"llama-3.3-70b-versatile\",  # or \"llama-3.3-70b-versatile\" if available\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant for project retrieval.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        \"https://api.groq.com/openai/v1/chat/completions\",\n",
    "        headers={\"Authorization\": f\"Bearer {GROQ_API_KEY}\", \"Content-Type\": \"application/json\"},\n",
    "        json=data\n",
    "    )\n",
    "\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93bd31c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I have projects related to cancer detection. Specifically, I have two repositories that focus on classifying chest X-rays to detect lung cancer adenocarcinoma:\n",
      "\n",
      "1. **ChestXray-Cancer-Detection**: This project utilizes a modular production-ready pipeline with tools like DVC, MLflow, and Dagshub for experiment tracking, reproducibility, and scalability. You can find it at: https://github.com/cleavestone/ChestXray-Cancer-Detection\n",
      "2. **Chest X-ray Cancer Classification**: This project provides an end-to-end deep learning system that classifies chest X-ray images as normal or adenocarcinoma using VGG16 transfer learning. The repository is located at: https://github.com/cleave/Chest X-ray Cancer Classification\n",
      "\n",
      "Both projects aim to assist in the early and accurate diagnosis of lung cancer, potentially improving patient outcomes.\n"
     ]
    }
   ],
   "source": [
    "def rag_pipeline(user_query):\n",
    "    matches = retrieve_from_pinecone(user_query)\n",
    "    if not matches:\n",
    "        return \"No relevant projects found.\"\n",
    "\n",
    "    context = build_context(matches)\n",
    "    answer = generate_answer(user_query, context)\n",
    "    return answer\n",
    "\n",
    "# Example\n",
    "query = \"Do you have any project related to cancer detection?\"\n",
    "print(rag_pipeline(query))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
